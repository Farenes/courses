# Лабораторная №4. Разработка поискового робота (Crawler)
## Тема и цель работы
Тема: разработка приложения для сбора и анализа веб-контента (Web Crawler).

Цель работы:
- Изучить принципы сетевого взаимодействия и протокола HTTP.
- Освоить методы парсинга HTML-документов.
- Получить навыки многопоточной/асинхронной обработки данных для ускорения работы приложения.
- Реализовать алгоритмы базовой текстовой аналитики для обработки собранных данных.

## Общая постановка задачи
Необходимо разработать консольное приложение (или приложение с минимальным GUI), которое выполняет обход (crawling) заданного веб-сайта (домена), собирает текстовое содержимое со страниц и проводит его анализ согласно варианту задания.

Приложение должно:
- Принимать на вход стартовый URL (например, https://example.com).
- Скачивать HTML-код страницы по указанному адресу.
- Извлекать из скачанной страницы все ссылки, ведущие на тот же домен (внутренние ссылки), и добавлять их в очередь на обход.
- Ограничивать глубину обхода (например, не переходить по ссылкам, находящимся глубже 3 уровня от стартовой страницы).
- Очищать HTML от тегов и извлекать "чистый" текст для анализа.
- Проводить аналитику по собранному тексту в соответствии с вариантом задания.
- Сохранять результаты анализа в файл (например, JSON, CSV или TXT).
- Избегать повторного скачивания одной и той же страницы.

## Функциональные требования
**Обработка HTTP**: Корректная обработка кодов ответа сервера (200, 404, 403, 500). Таймауты на соединение.

**Парсинг**: для парсинга HTML можно использовать специализированную библиотеку (например, Jsoup для Java, BeautifulSoup для Python, HtmlAgilityPack для C#).

**Производительность**: обход должен выполняться в несколько потоков (или асинхронно), чтобы ускорить процесс.

**Интерфейс**: программа должна выводить в консоль информацию о прогрессе (какая страница обрабатывается, сколько найдено, сколько осталось в очереди).

**Обработка ошибок**: приложение не должно "падать" при ошибках сети или парсинга одной страницы, а должно логировать ошибку и продолжать работу.

## Отчет о выполнении
1. Титульный лист
2. Цель работы.
3. Краткое описание архитектуры приложения: перечислить основные классы/модули и их ответственность. Приложить схему взаимодействия компонентов (можно от руки, но разборчиво).
4. Инструкция по запуску: какие библиотеки нужно установить, как запустить программу.
5. Результаты тестирования: скриншоты работы программы на выданном преподавателем сайте.
6. Анализ результатов: вывод по итогам анализа (например, "самое частое слово на сайте — 'интернет', встретилось 150 раз").
7. Листинг кода: Распечатки ключевых фрагментов кода (не обязательно весь проект целиком, но основные алгоритмы должны быть видны).
8. Ссылка на github с полным кодом проекта.

## Варианты
1. Сайт новостей - https://ura.news/ (топ 10 часто используемых слов)
2. База знаний - https://en.wikipedia.org/ (Сбор информации по определенной теме, с определенной глубиной)
3. Сайт новостей - https://www.interfax.ru/ (топ 10 часто используемых слов)
4. Сайт новостей - https://www.vedomosti.ru/ (топ 10 часто используемых слов)
5. Сайт вакансий - https://hh.ru/ (топ вакансий)
6. Сайт новостей - https://eadaily.com/ (топ 10 часто используемых слов)
7. Сайт статей - https://habr.com/ (топ 10 часто используемых слов)
8. Сайт новостей - https://lenta.ru/ (топ 10 часто используемых слов)
9. База знаний - https://neolurk.org/ (Сбор информации по определенной теме, с определенной глубиной)
10. Сайт новостей - https://dzen.ru/ (топ 10 часто используемых слов)